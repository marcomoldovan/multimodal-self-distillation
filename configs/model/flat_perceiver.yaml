_target_: src.models.module.LatentPredictionPretraining
ema_decay: 0.999
ema_end_decay: 0.9999
ema_anneal_end_step: 300000
switch_student_teacher_per_epoch: false

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0005

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  _partial_: true
  T_0: 10

criterion:
  _target_: src.models.components.criterion.LatentPredictionLoss
  num_hidden_layers_to_predict: 3
  reduction: 'mean'
  beta: 1.0

model:
  _target_: src.models.components.perceiver.PerceiverModel
  is_training: True
  is_student: False
  d_model: 704
  num_latents: 784
  d_latents: 512
  num_blocks: 1
  num_self_attention_heads: 8
  num_self_attends_per_block: 8
  num_cross_attention_heads: 1
  qk_channels: Null
  v_channels: Null
  cross_attention_shape_for_attention: kv
  self_attention_widening_factor: 1
  cross_attention_widening_factor: 1
  attention_probs_dropout_prob: 0.1
  chunk_size_feed_forward: 0
  kv_dim: Null
  use_query_residual: True
  mask_time_prob: 0.05
  mask_time_length: 10
  use_simsiam_projector: False

  input_preprocessor:
    _target_: src.models.components.preprocessor.PerceiverMultimodalPreprocessor
    modalities:
      text:
        _target_: src.models.components.preprocessor.PerceiverTextPreprocessor
        d_model: 504 #! ${model.d_model}
        vocab_size: 262
        max_position_embeddings: 2048
      audio:
        _target_: src.models.components.preprocessor.PerceiverAudioPreprocessor
        prep_type: patches
        samples_per_patch: 96 # seq length must be multiple of this
        position_encoding_type: fourier
        concat_or_add_pos: concat
        out_channels: 64
        project_pos_dim: -1
        num_frames: 1
        audio_samples_per_frame: 1920
      image:
        _target_: src.models.components.preprocessor.PerceiverImagePreprocessor
        prep_type: pixels
        spatial_downsample: 1
        temporal_downsample: 1
        position_encoding_type: fourier
        in_channels: 3
        out_channels: 64
        conv_after_patching: False
        conv_after_patching_in_channels: 54  # only relevant when conv_after_patching = True
        conv2d_use_batchnorm: True
        concat_or_add_pos: concat
        project_pos_dim: -1
        num_frames: 1 
        image_size: 56
      video:
        _target_: src.models.components.preprocessor.PerceiverImagePreprocessor
        prep_type: patches
        spatial_downsample: 1
        temporal_downsample: 1
        position_encoding_type: fourier
        in_channels: 3
        out_channels: 64
        conv_after_patching: False
        conv_after_patching_in_channels: 54  # only relevant when conv_after_patching = True
        conv2d_use_batchnorm: True
        concat_or_add_pos: concat
        project_pos_dim: -1
        num_frames: 16
        image_size: 56
      # label:
      #   _target_: src.models.components.preprocessor.PerceiverOneHotPreprocessor
      #   num_labels: 1000