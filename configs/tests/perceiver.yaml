model:
  _target_: src.models.components.perceiver.PerceiverModel
  is_training: True
  is_student: False
  d_model: 704
  num_latents: 784
  d_latents: 512
  num_blocks: 1
  num_self_attention_heads: 8
  num_self_attends_per_block: 8
  num_cross_attention_heads: 1
  qk_channels: Null
  v_channels: Null
  cross_attention_shape_for_attention: kv
  self_attention_widening_factor: 1
  cross_attention_widening_factor: 1
  attention_probs_dropout_prob: 0.1
  chunk_size_feed_forward: 0 # found in PretrainedConfig        
  kv_dim: Null
  use_query_residual: True
  mask_time_prob: 0.05
  mask_time_length: 10

  input_preprocessor:
    _target_: src.models.components.preprocessor.PerceiverMultimodalPreprocessor
    modalities:
      audio:
        _target_: src.models.components.preprocessor.PerceiverAudioPreprocessor
        prep_type: patches
        samples_per_patch: 96
        position_encoding_type: fourier
        concat_or_add_pos: concat
        out_channels: 64
        project_pos_dim: -1
        fourier_position_encoding_kwargs:
          num_bands: 192
          max_resolution: (1*1920) # config.num_frames * config.audio_samples_per_frame #! num_frames > 1 for video
          sine_only: False
          concat_pos: True
      image:
        _target_: src.models.components.preprocessor.PerceiverImagePreprocessor
        prep_type: conv
        spatial_downsample: 4
        temporal_downsample: 1
        position_encoding_type: fourier
        in_channels: 3
        out_channels: 64
        conv_after_patching: False
        conv_after_patching_in_channels: 54  # only relevant when conv_after_patching = True
        conv2d_use_batchnorm: True
        concat_or_add_pos: concat
        project_pos_dim: -1
        num_frames: 1
        image_size: 56
        fourier_position_encoding_kwargs: 
          num_bands: 32
          max_resolution: (1, 56, 56) # config.num_frames, config.image_size, config.image_size #! num_frames > 1 for video
          sine_only: False
          concat_pos: True
      text:
        _target_: src.models.components.preprocessor.PerceiverTextPreprocessor
        d_model: 512
        vocab_size: 262
        max_position_embeddings: 2048
      label:
        _target_: src.models.components.preprocessor.PerceiverOneHotPreprocessor
        num_labels: 1000
