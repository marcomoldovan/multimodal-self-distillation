{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatherLayer(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Gathers tensors from all process and supports backward propagation\n",
    "    for the gradients across processes.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        if dist.is_available() and dist.is_initialized():\n",
    "            output = [torch.zeros_like(x) for _ in range(dist.get_world_size())]\n",
    "            dist.all_gather(output, x)\n",
    "        else:\n",
    "            output = [x]\n",
    "        return tuple(output)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grads):\n",
    "        if dist.is_available() and dist.is_initialized():\n",
    "            all_gradients = torch.stack(grads)\n",
    "            dist.all_reduce(all_gradients)\n",
    "            grad_out = all_gradients[get_rank()]\n",
    "        else:\n",
    "            grad_out = grads[0]\n",
    "        return grad_out\n",
    "\n",
    "def get_rank():\n",
    "    if dist.is_available() and dist.is_initialized():\n",
    "        return dist.get_rank()\n",
    "    return 0\n",
    "\n",
    "def gather(X, dim=0):\n",
    "    \"\"\"Gathers tensors from all processes, supporting backward propagation.\"\"\"\n",
    "    return torch.cat(GatherLayer.apply(X), dim=dim)\n",
    "class VICRegLoss(nn.Module):\n",
    "    # https://github.com/vturrisi/solo-learn/blob/main/solo/losses/vicreg.py\n",
    "    def __init__(\n",
    "        self,\n",
    "        sim_loss_weight: float = 25.0,\n",
    "        var_loss_weight: float = 25.0,\n",
    "        cov_loss_weight: float = 1.0,\n",
    "        ) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            sim_loss_weight (float, optional): _description_. Defaults to 25.0.\n",
    "            var_loss_weight (float, optional): _description_. Defaults to 25.0.\n",
    "            cov_loss_weight (float, optional): _description_. Defaults to 1.0.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sim_loss_weight = sim_loss_weight\n",
    "        self.var_loss_weight = var_loss_weight\n",
    "        self.cov_loss_weight = cov_loss_weight\n",
    "\n",
    "    \n",
    "    def invariance_loss(self, z1: torch.Tensor, z2: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes mse loss given batch of projected features z1 from view 1 and\n",
    "        projected features z2 from view 2.\n",
    "        Args:\n",
    "            z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n",
    "            z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n",
    "        Returns:\n",
    "            torch.Tensor: invariance loss (mean squared error).\n",
    "        \"\"\"\n",
    "\n",
    "        return F.mse_loss(z1, z2)\n",
    "\n",
    "\n",
    "    def variance_loss(self, z1: torch.Tensor, z2: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes variance loss given batch of projected features z1 from view 1 and\n",
    "        projected features z2 from view 2.\n",
    "        Args:\n",
    "            z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n",
    "            z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n",
    "        Returns:\n",
    "            torch.Tensor: variance regularization loss.\n",
    "        \"\"\"\n",
    "\n",
    "        eps = 1e-4\n",
    "        std_z1 = torch.sqrt(z1.var(dim=0) + eps)\n",
    "        std_z2 = torch.sqrt(z2.var(dim=0) + eps)\n",
    "        std_loss = torch.mean(F.relu(1 - std_z1)) + torch.mean(F.relu(1 - std_z2))\n",
    "        return std_loss\n",
    "\n",
    "\n",
    "    def covariance_loss(self, z1: torch.Tensor, z2: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes covariance loss given batch of projected features z1 from view 1 and\n",
    "        projected features z2 from view 2.\n",
    "        Args:\n",
    "            z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n",
    "            z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n",
    "        Returns:\n",
    "            torch.Tensor: covariance regularization loss.\n",
    "        \"\"\"\n",
    "\n",
    "        N, D = z1.size()\n",
    "\n",
    "        z1 = z1 - z1.mean(dim=0)\n",
    "        z2 = z2 - z2.mean(dim=0)\n",
    "        cov_z1 = (z1.T @ z1) / (N - 1)\n",
    "        cov_z2 = (z2.T @ z2) / (N - 1)\n",
    "\n",
    "        diag = torch.eye(D, device=z1.device)\n",
    "        cov_loss = cov_z1[~diag.bool()].pow_(2).sum() / D + cov_z2[~diag.bool()].pow_(2).sum() / D\n",
    "        return cov_loss\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        z1: torch.Tensor,\n",
    "        z2: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Computes VICReg's loss given batch of projected features z1 from view 1 and\n",
    "        projected features z2 from view 2.\n",
    "        Args:\n",
    "            z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n",
    "            z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n",
    "        Returns:\n",
    "            torch.Tensor: VICReg loss.\n",
    "        \"\"\"\n",
    "\n",
    "        sim_loss = self.invariance_loss(z1, z2)\n",
    "\n",
    "        # vicreg's official code gathers the tensors here\n",
    "        # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
    "        z1, z2 = gather(z1), gather(z2)\n",
    "\n",
    "        var_loss = self.variance_loss(z1, z2)\n",
    "        cov_loss = self.covariance_loss(z1, z2)\n",
    "\n",
    "        loss = self.sim_loss_weight * sim_loss + self.var_loss_weight * var_loss + self.cov_loss_weight * cov_loss\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.2148)\n"
     ]
    }
   ],
   "source": [
    "vicreg_loss = VICRegLoss()\n",
    "\n",
    "x = torch.randn(20, 128)\n",
    "y = torch.randn(20, 128)\n",
    "\n",
    "loss = vicreg_loss(x, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriterionOutput:\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_loss: torch.Tensor = torch.tensor(0.0),\n",
    "        align_loss: torch.Tensor = None,\n",
    "    ) -> None:\n",
    "        self.latent_loss = latent_loss\n",
    "        self.align_loss = align_loss\n",
    "        self.total_loss = latent_loss + align_loss\n",
    "        \n",
    "    def set_attributes(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss \u001b[39m=\u001b[39m CriterionOutput(align_loss\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(\u001b[39m1.0\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mtotal_loss)\n",
      "Cell \u001b[1;32mIn [6], line 9\u001b[0m, in \u001b[0;36mCriterionOutput.__init__\u001b[1;34m(self, latent_loss, align_loss)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_loss \u001b[39m=\u001b[39m latent_loss\n\u001b[0;32m      8\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malign_loss \u001b[39m=\u001b[39m align_loss\n\u001b[1;32m----> 9\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_loss \u001b[39m=\u001b[39m latent_loss \u001b[39m+\u001b[39;49m align_loss\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "loss = CriterionOutput(align_loss=torch.tensor(1.0))\n",
    "print(loss.total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ac8a2bc69d4b2bdc42aaccd63f192d886c476dacd93adfa548f17911c905576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
