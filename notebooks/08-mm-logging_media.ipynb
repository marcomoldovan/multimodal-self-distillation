{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from torchmetrics import RetrievalMRR\n",
    "from transformers import BertTokenizerFast, PerceiverFeatureExtractor\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "feature_extractor = PerceiverFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['##lean consisting robert eddie germanic unsuccessful august closeness mariano karachi', 'simulation financially pas potentially sinister pleasure brewers [unused903] literallyudge', 'oaxaca Ê” clapping armoured hummed 227 mckenziepid remains backwards', '##aged good commander knowing phased acquire cargo organisation [unused773] lexi', 'guerre qualified rated sentences barnard explainssneriens hendrix spicy']\n"
     ]
    }
   ],
   "source": [
    "ids = torch.randint(low=100, high=30000, size=(5, 10))\n",
    "text = tokenizer.batch_decode(ids, skip_special_tokens=True)\n",
    "text = wandb.Table(data=[[sent] for sent in text], columns=['text'])\n",
    "print(text.get_column('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def knn_core(prediction_features, query_features, labels, k, temperature, zero_diagonal, num_classes, batch_size):\n",
    "    similarity = F.normalize(query_features) @ F.normalize(prediction_features).t()\n",
    "    similarity_ground_truth = torch.diag(similarity)\n",
    "\n",
    "    torch.diagonal(similarity, 0).zero_() if zero_diagonal else None\n",
    "    distances, indices = similarity.topk(k, largest=True, sorted=True)\n",
    "    candidates = labels.view(1, -1).expand(batch_size, -1)\n",
    "    retrieved_neighbors = torch.gather(candidates, 1, indices)\n",
    "    \n",
    "    retrieval_one_hot = torch.zeros(batch_size * k, num_classes)\n",
    "    retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n",
    "    distances_transform = (distances / temperature).exp_()\n",
    "    \n",
    "    probs = torch.sum(\n",
    "        torch.mul(\n",
    "            retrieval_one_hot.view(batch_size, -1, num_classes),\n",
    "            distances_transform.view(batch_size, -1, 1),\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    probs.div_(probs.sum(dim=1, keepdim=True))\n",
    "    probs_sorted, predictions = probs.sort(1, True)\n",
    "    \n",
    "    return similarity, similarity_ground_truth, distances, indices, probs, probs_sorted, predictions\n",
    "    \n",
    "\n",
    "def k_nearest_neighbor(\n",
    "    prediction_features: torch.Tensor, \n",
    "    query_features: torch.Tensor = None, \n",
    "    labels: torch.Tensor = None, \n",
    "    k: int = 20, \n",
    "    chunking: bool = True\n",
    "    ) -> Tuple:\n",
    "    \n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "        \n",
    "    temperature = 0.1\n",
    "    num_classes = len(set(list(labels.numpy())))\n",
    "    \n",
    "    if query_features is None:\n",
    "        # means that similarity is computed between prediction features and itself\n",
    "        query_features = prediction_features\n",
    "        zero_diagonal = True\n",
    "        trim_preds = False\n",
    "    else:\n",
    "        zero_diagonal = False\n",
    "        trim_preds = True\n",
    "        \n",
    "    if chunking:\n",
    "        num_chunks = 10 #TODO this was 100 but had to be reduced to 10 to avoid OOM for local testing\n",
    "        num_test_samples = query_features.size()[0]\n",
    "        samples_per_chunk = num_test_samples // num_chunks\n",
    "            \n",
    "        for idx in range(0, num_test_samples, samples_per_chunk):\n",
    "            \n",
    "            \n",
    "            query_chunk_features = query_features[\n",
    "                idx : min((idx + samples_per_chunk), num_test_samples), :\n",
    "            ]\n",
    "            chunk_labels = labels[\n",
    "                idx : min((idx + samples_per_chunk), num_test_samples)\n",
    "            ]\n",
    "            \n",
    "            batch_size = chunk_labels.shape[0]\n",
    "            \n",
    "            similarity, similarity_ground_truth, distances, indices, probs, probs_sorted, preds = knn_core(prediction_features, query_chunk_features, labels, k, temperature, zero_diagonal, num_classes, batch_size)\n",
    "            \n",
    "            probabilities.append(probs)\n",
    "            predictions.append(preds)\n",
    "        \n",
    "        probabilities = torch.cat(probabilities, dim=0)\n",
    "        predictions = torch.cat(predictions, dim=0)\n",
    "        \n",
    "        return probabilities, predictions, labels\n",
    "    else:\n",
    "        batch_size = labels.shape[0]\n",
    "        return knn_core(prediction_features, query_features, labels, k, temperature, zero_diagonal, num_classes, batch_size)\n",
    "        \n",
    "\n",
    "\n",
    "def k_nearest_neighbor_simple(\n",
    "    prediction_features: torch.Tensor, \n",
    "    query_features: torch.Tensor = None, \n",
    "    labels: torch.Tensor = None, \n",
    "    k: int = 20, \n",
    "    ) -> Tuple:\n",
    "        \n",
    "    temperature = 0.1\n",
    "    num_classes = len(set(list(labels.numpy())))\n",
    "    \n",
    "    if query_features is None:\n",
    "        # means that similarity is computed between prediction features and itself\n",
    "        query_features = prediction_features\n",
    "        zero_diagonal = True\n",
    "        trim_preds = False\n",
    "    else:\n",
    "        zero_diagonal = False\n",
    "        trim_preds = True\n",
    "        \n",
    "    batch_size = labels.shape[0]\n",
    "    \n",
    "    similarity = F.normalize(query_features) @ F.normalize(prediction_features).t()\n",
    "    similarity_ground_truth = torch.diag(similarity)\n",
    "\n",
    "    torch.diagonal(similarity, 0).zero_() if zero_diagonal else None\n",
    "    distances, indices = similarity.topk(k, largest=True, sorted=True)\n",
    "    candidates = labels.view(1, -1).expand(batch_size, -1)\n",
    "    retrieved_neighbors = torch.gather(candidates, 1, indices)\n",
    "    \n",
    "    retrieval_one_hot = torch.zeros(batch_size * k, num_classes)\n",
    "    retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n",
    "    distances_transform = (distances / temperature).exp_()\n",
    "    \n",
    "    probs = torch.sum(\n",
    "        torch.mul(\n",
    "            retrieval_one_hot.view(batch_size, -1, num_classes),\n",
    "            distances_transform.view(batch_size, -1, 1),\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    probs.div_(probs.sum(dim=1, keepdim=True))\n",
    "    probs_sorted, predictions = probs.sort(1, True)\n",
    "    \n",
    "    return probs, predictions, labels, distances, indices, similarity_ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['uhm what is going on you guys?', <wandb.sdk.data_types.image.Image object at 0x0000028AB50B3970>, tensor(-0.0881), <wandb.sdk.data_types.image.Image object at 0x0000028AB50B32E0>, tensor(0.1368)], [\"I think you're gonna wanna see this!\", <wandb.sdk.data_types.image.Image object at 0x0000028AB50D5D90>, tensor(0.1661), <wandb.sdk.data_types.image.Image object at 0x0000028AADB08A30>, tensor(0.1661)], [\"It's best if we split up.\", <wandb.sdk.data_types.image.Image object at 0x0000028AB50B3AF0>, tensor(-0.1086), <wandb.sdk.data_types.image.Image object at 0x0000028AB50B3280>, tensor(0.0863)], [\"I wouldn't do that if I were you!\", <wandb.sdk.data_types.image.Image object at 0x0000028AB50B3190>, tensor(0.0234), <wandb.sdk.data_types.image.Image object at 0x0000028AB50EAFA0>, tensor(0.2125)], [\"That's gonna leave a mark.\", <wandb.sdk.data_types.image.Image object at 0x0000028AB50D5CD0>, tensor(-0.0542), <wandb.sdk.data_types.image.Image object at 0x0000028AB50B3F70>, tensor(0.0511)], ['We are done!', <wandb.sdk.data_types.image.Image object at 0x0000028AB50B3310>, tensor(-0.0376), <wandb.sdk.data_types.image.Image object at 0x0000028AB4F69AF0>, tensor(0.1944)]]\n"
     ]
    }
   ],
   "source": [
    "text = [\"uhm what is going on you guys?\", \"I think you're gonna wanna see this!\", \"It's best if we split up.\", \"I wouldn't do that if I were you!\", \"That's gonna leave a mark.\", \"We are done!\"]\n",
    "text_pred = torch.randn(6, 64)\n",
    "images = torch.randn(6, 3, 224, 224)\n",
    "img_pred = torch.randn(6, 64)\n",
    "labels = torch.tensor(list(range(img_pred.size()[0])))\n",
    "\n",
    "similarity, similarity_ground_truth, top_k_distances, top_k_indices, probs, probs_sorted, predictions = k_nearest_neighbor(img_pred, text_pred, labels, 3, False)\n",
    "\n",
    "wandb_imgs = [[wandb.Image(img, caption=text[i]) for i, img in enumerate(images)]]\n",
    "\n",
    "table = wandb.Table(columns=['query', 'ground truth', 'similarity ground truth', '#1 prediction', 'similarity #1 prediction'])\n",
    "\n",
    "for query, image, sim_gt, top_k_idx, top_k_dist in zip(text, images, similarity_ground_truth, top_k_indices, top_k_distances):\n",
    "    table.add_data(\n",
    "        query, \n",
    "        wandb.Image(image, caption=query), \n",
    "        sim_gt, \n",
    "        wandb.Image(images[top_k_idx[0]], caption=text[top_k_idx[0]]), \n",
    "        top_k_dist[0]\n",
    "    )\n",
    "\n",
    "print(table.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 4000]) torch.Size([4000, 4000]) torch.Size([4000])\n"
     ]
    }
   ],
   "source": [
    "q = torch.randn(4000, 64)\n",
    "p = torch.randn(4000, 64)\n",
    "l = torch.tensor(list(range(4000)))\n",
    "\n",
    "probabilities, predictions, labels = k_nearest_neighbor(p, q, l, 3, True)\n",
    "print(probabilities.shape, predictions.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ac8a2bc69d4b2bdc42aaccd63f192d886c476dacd93adfa548f17911c905576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
