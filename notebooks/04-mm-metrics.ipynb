{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics import Accuracy, Recall, RetrievalMRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbor(\n",
    "    prediction_features: torch.Tensor, \n",
    "    query_features: torch.Tensor = None, \n",
    "    labels: torch.Tensor = None, \n",
    "    k: int = 20, \n",
    "    temperature: float = 0.1\n",
    "    ) -> Tuple:\n",
    "    \n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "        \n",
    "    num_classes = len(set(list(labels.numpy())))\n",
    "    \n",
    "    if query_features is None:\n",
    "        # means that similarity is computed between prediction features and itself\n",
    "        query_features = prediction_features\n",
    "        zero_diagonal = True\n",
    "        trim_preds = False\n",
    "    else:\n",
    "        zero_diagonal = False\n",
    "        trim_preds = True\n",
    "        \n",
    "    num_chunks = 100\n",
    "    num_test_samples = query_features.size()[0]\n",
    "    samples_per_chunk = num_test_samples // num_chunks\n",
    "        \n",
    "    for idx in range(0, num_test_samples, samples_per_chunk):\n",
    "        \n",
    "        chunk_features = query_features[\n",
    "            idx : min((idx + samples_per_chunk), num_test_samples), :\n",
    "        ]\n",
    "        chunk_labels = labels[\n",
    "            idx : min((idx + samples_per_chunk), num_test_samples)\n",
    "        ]\n",
    "        \n",
    "        batch_size = chunk_labels.shape[0]\n",
    "        \n",
    "        similarity = F.normalize(chunk_features) @ F.normalize(prediction_features).t() \n",
    "        torch.diagonal(similarity, 0).zero_() if zero_diagonal else None\n",
    "        distances, indices = similarity.topk(k, largest=True, sorted=True)\n",
    "        candidates = labels.view(1, -1).expand(batch_size, -1)\n",
    "        retrieved_neighbors = torch.gather(candidates, 1, indices)\n",
    "        \n",
    "        retrieval_one_hot = torch.zeros(batch_size * k, num_classes)\n",
    "        retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n",
    "        distances_transform = (distances / temperature).exp_()\n",
    "        \n",
    "        probs = torch.sum(\n",
    "            torch.mul(\n",
    "                retrieval_one_hot.view(batch_size, -1, num_classes),\n",
    "                distances_transform.view(batch_size, -1, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "        probs.div_(probs.sum(dim=1, keepdim=True))\n",
    "        probs_sorted, preds = probs.sort(1, True)\n",
    "        \n",
    "        probabilities.append(probs)\n",
    "        predictions.append(preds)\n",
    "    \n",
    "    probabilities = torch.cat(probabilities, dim=0)\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    \n",
    "    return probabilities, predictions, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9900)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_unimodal = torch.rand(40000, 64)\n",
    "\n",
    "num_classes = 1000\n",
    "labels_unimodal = torch.randint(0, num_classes, (features_unimodal.size()[0],))\n",
    "\n",
    "probabilities_unimodal, _, labels_generated_unimodal, num_classes_unimodal = k_nearest_neighbor(prediction_features=features_unimodal, labels=labels_unimodal)\n",
    "\n",
    "acc = Accuracy(num_classes=num_classes_unimodal, top_k=5)\n",
    "acc(probabilities_unimodal, labels_unimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_multimodal = torch.rand(4000, 64)\n",
    "queries_multimodal = torch.randn(4000, 64)\n",
    "\n",
    "labels_multimodal = torch.tensor(list(range(features_multimodal.size()[0])))\n",
    "\n",
    "probabilities_multimodal, _, labels_generated_multimodal, num_classes_multimodal = k_nearest_neighbor(prediction_features=features_multimodal, query_features=queries_multimodal, labels=labels_multimodal)\n",
    "\n",
    "rec = Recall(num_classes=num_classes_multimodal, top_k=5)\n",
    "rec.compute(probabilities_multimodal, labels_multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of predictions: 6.4 GB\n"
     ]
    }
   ],
   "source": [
    "# size of tensor in GB\n",
    "print(f\"Size of predictions: {probabilities_multimodal.size()[0] * probabilities_multimodal.size()[1] * 4 / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meye(\u001b[39mlen\u001b[39m(labels))\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     12\u001b[0m \u001b[39m# print(target)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mprint\u001b[39m(mrr(preds, target, indexes\u001b[39m=\u001b[39mindexes))\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\metric.py:245\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_reduce_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\metric.py:309\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    310\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m    312\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\metric.py:391\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    393\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\retrieval\\base.py:102\u001b[0m, in \u001b[0;36mRetrievalMetric.update\u001b[1;34m(self, preds, target, indexes)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m indexes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mArgument `indexes` cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 102\u001b[0m indexes, preds, target \u001b[39m=\u001b[39m _check_retrieval_inputs(\n\u001b[0;32m    103\u001b[0m     indexes, preds, target, allow_non_binary_target\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_non_binary_target, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindexes\u001b[39m.\u001b[39mappend(indexes)\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreds\u001b[39m.\u001b[39mappend(preds)\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:558\u001b[0m, in \u001b[0;36m_check_retrieval_inputs\u001b[1;34m(indexes, preds, target, allow_non_binary_target, ignore_index)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_retrieval_inputs\u001b[39m(\n\u001b[0;32m    535\u001b[0m     indexes: Tensor,\n\u001b[0;32m    536\u001b[0m     preds: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     ignore_index: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    540\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor, Tensor]:\n\u001b[0;32m    541\u001b[0m     \u001b[39m\"\"\"Check ``indexes``, ``preds`` and ``target`` tensors are of the same shape and of the correct data type.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \n\u001b[0;32m    543\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[39m        target: as ``torch.long``\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 558\u001b[0m     \u001b[39mif\u001b[39;00m indexes\u001b[39m.\u001b[39;49mshape \u001b[39m!=\u001b[39m preds\u001b[39m.\u001b[39mshape \u001b[39mor\u001b[39;00m preds\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m target\u001b[39m.\u001b[39mshape:\n\u001b[0;32m    559\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`indexes`, `preds` and `target` must be of the same shape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m indexes\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mlong:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "text_pred = torch.randn(100, 64)\n",
    "img_pred = torch.randn(100, 64)\n",
    "labels = torch.tensor(list(range(img_pred.size()[0])))\n",
    "\n",
    "probs, predictions, labels = k_nearest_neighbor(prediction_features=img_pred, query_features=text_pred, labels=labels, k=100)\n",
    "\n",
    "mrr = RetrievalMRR()\n",
    "indexes = torch.tensor([[n]*len(labels) for n in range(len(labels))], dtype=torch.long).flatten()\n",
    "preds = probs.flatten()\n",
    "target = torch.eye(len(labels)).flatten()\n",
    "print(mrr(preds, target, indexes=indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('multimodal-ssl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ac8a2bc69d4b2bdc42aaccd63f192d886c476dacd93adfa548f17911c905576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
