{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics import Accuracy, Recall, RetrievalMRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbor(\n",
    "    prediction_features: torch.Tensor, \n",
    "    query_features: torch.Tensor = None, \n",
    "    labels: torch.Tensor = None, \n",
    "    k: int = 20, \n",
    "    temperature: float = 0.1\n",
    "    ) -> Tuple:\n",
    "    \n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "        \n",
    "    num_classes = len(set(list(labels.numpy())))\n",
    "    \n",
    "    if query_features is None:\n",
    "        # means that similarity is computed between prediction features and itself\n",
    "        query_features = prediction_features\n",
    "        zero_diagonal = True\n",
    "        trim_preds = False\n",
    "    else:\n",
    "        zero_diagonal = False\n",
    "        trim_preds = True\n",
    "        \n",
    "    num_chunks = 100\n",
    "    num_test_samples = query_features.size()[0]\n",
    "    samples_per_chunk = num_test_samples // num_chunks\n",
    "        \n",
    "    for idx in range(0, num_test_samples, samples_per_chunk):\n",
    "        \n",
    "        chunk_features = query_features[\n",
    "            idx : min((idx + samples_per_chunk), num_test_samples), :\n",
    "        ]\n",
    "        chunk_labels = labels[\n",
    "            idx : min((idx + samples_per_chunk), num_test_samples)\n",
    "        ]\n",
    "        \n",
    "        batch_size = chunk_labels.shape[0]\n",
    "        \n",
    "        similarity = F.normalize(chunk_features) @ F.normalize(prediction_features).t() \n",
    "        torch.diagonal(similarity, 0).zero_() if zero_diagonal else None\n",
    "        distances, indices = similarity.topk(k, largest=True, sorted=True)\n",
    "        candidates = labels.view(1, -1).expand(batch_size, -1)\n",
    "        retrieved_neighbors = torch.gather(candidates, 1, indices)\n",
    "        \n",
    "        retrieval_one_hot = torch.zeros(batch_size * k, num_classes)\n",
    "        retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n",
    "        distances_transform = (distances / temperature).exp_()\n",
    "        \n",
    "        probs = torch.sum(\n",
    "            torch.mul(\n",
    "                retrieval_one_hot.view(batch_size, -1, num_classes),\n",
    "                distances_transform.view(batch_size, -1, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "        probs.div_(probs.sum(dim=1, keepdim=True))\n",
    "        probs_sorted, preds = probs.sort(1, True)\n",
    "        \n",
    "        probabilities.append(probs)\n",
    "        predictions.append(preds)\n",
    "    \n",
    "    probabilities = torch.cat(probabilities, dim=0)\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    \n",
    "    return probabilities, predictions, labels, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9900)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_unimodal = torch.rand(40000, 64)\n",
    "\n",
    "num_classes = 1000\n",
    "labels_unimodal = torch.randint(0, num_classes, (features_unimodal.size()[0],))\n",
    "\n",
    "probabilities_unimodal, _, labels_generated_unimodal, num_classes_unimodal = k_nearest_neighbor(prediction_features=features_unimodal, labels=labels_unimodal)\n",
    "\n",
    "acc = Accuracy(num_classes=num_classes_unimodal, top_k=5)\n",
    "acc(probabilities_unimodal, labels_unimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: The ``compute`` method of metric Recall was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m probabilities_multimodal, _, labels_generated_multimodal, num_classes_multimodal \u001b[39m=\u001b[39m k_nearest_neighbor(prediction_features\u001b[39m=\u001b[39mfeatures_multimodal, query_features\u001b[39m=\u001b[39mqueries_multimodal, labels\u001b[39m=\u001b[39mlabels_multimodal)\n\u001b[0;32m      8\u001b[0m rec \u001b[39m=\u001b[39m Recall(num_classes\u001b[39m=\u001b[39mnum_classes_multimodal, top_k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m rec\u001b[39m.\u001b[39mcompute(probabilities_multimodal, labels_multimodal)\n",
      "File \u001b[1;32mc:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\torchmetrics\\metric.py:531\u001b[0m, in \u001b[0;36mMetric._wrap_compute.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39m# compute relies on the sync context manager to gather the states across processes and apply reduction\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[39m# if synchronization happened, the current rank accumulated states will be restored to keep\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[39m# accumulation going if ``should_unsync=True``,\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_context(\n\u001b[0;32m    527\u001b[0m     dist_sync_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdist_sync_fn,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    528\u001b[0m     should_sync\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_sync,\n\u001b[0;32m    529\u001b[0m     should_unsync\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_unsync,\n\u001b[0;32m    530\u001b[0m ):\n\u001b[1;32m--> 531\u001b[0m     value \u001b[39m=\u001b[39m compute(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m _squeeze_if_scalar(value)\n\u001b[0;32m    534\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed\n",
      "\u001b[1;31mTypeError\u001b[0m: compute() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "features_multimodal = torch.rand(4000, 64)\n",
    "queries_multimodal = torch.randn(4000, 64)\n",
    "\n",
    "labels_multimodal = torch.tensor(list(range(features_multimodal.size()[0])))\n",
    "\n",
    "probabilities_multimodal, _, labels_generated_multimodal, num_classes_multimodal = k_nearest_neighbor(prediction_features=features_multimodal, query_features=queries_multimodal, labels=labels_multimodal)\n",
    "\n",
    "rec = Recall(num_classes=num_classes_multimodal, top_k=5)\n",
    "rec.compute(probabilities_multimodal, labels_multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of predictions: 6.4 GB\n"
     ]
    }
   ],
   "source": [
    "# size of tensor in GB\n",
    "print(f\"Size of predictions: {probabilities_multimodal.size()[0] * probabilities_multimodal.size()[1] * 4 / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = Recall(num_classes=len(labels_generated), top_k=5)\n",
    "rec(predictions_generated, labels_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('multimodal-ssl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ac8a2bc69d4b2bdc42aaccd63f192d886c476dacd93adfa548f17911c905576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
