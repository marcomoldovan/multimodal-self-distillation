{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\.venv\\multimodal-ssl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutput:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pooler_output: torch.Tensor,\n",
    "        last_hidden_state: torch.Tensor,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attentions: torch.Tensor,\n",
    "        cross_attentions: torch.Tensor    \n",
    "    ) -> None:\n",
    "        self.pooler_output = pooler_output\n",
    "        self.last_hidden_state = last_hidden_state\n",
    "        self.hidden_states = hidden_states\n",
    "        self.attentions = attentions\n",
    "        self.cross_attentions = cross_attentions\n",
    "\n",
    "class ForwardPassOutput:\n",
    "    def __init__(\n",
    "        self,\n",
    "        student_output = None,\n",
    "        teacher_output = None,\n",
    "        align_fuse: dict = None,\n",
    "        labels: torch.Tensor = None,\n",
    "        output_modalities: dict = None\n",
    "    ) -> None:\n",
    "        self.student_output = student_output\n",
    "        self.teacher_output = teacher_output\n",
    "        self.align_fuse = align_fuse\n",
    "        self.labels = labels\n",
    "        self.output_modalities = output_modalities\n",
    "        \n",
    "    def set_attributes(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_output = ModelOutput(pooler_output=torch.randn(64,128), last_hidden_state=torch.randn(64,256,128), hidden_states=[torch.randn(64,256,128)]*8, attentions=[torch.randn(64,8,256,256)]*8, cross_attentions=[torch.randn(64,1,256,299)])\n",
    "teacher_output = ModelOutput(pooler_output=torch.randn(64,128), last_hidden_state=torch.randn(64,256,128), hidden_states=[torch.randn(64,256,128)]*8, attentions=[torch.randn(64,8,256,256)]*8, cross_attentions=[torch.randn(64,1,256,299)])\n",
    "outputs = ForwardPassOutput(student_output=student_output, teacher_output=teacher_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.baeldung.com/cs/instance-vs-batch-normalization\n",
    "\n",
    "class LatentPredictionLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hidden_layers_to_predict: int,\n",
    "        reduction: str = \"mean\",\n",
    "        beta: float = 1.0        \n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_fn = nn.SmoothL1Loss(reduction=reduction, beta=beta)\n",
    "        \n",
    "        self.num_hidden_layers_to_predict = num_hidden_layers_to_predict\n",
    "        \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        fwd_output: ForwardPassOutput,\n",
    "        ) -> torch.Tensor:\n",
    "        \n",
    "        x = fwd_output.student_output.hidden_states[-1:][0]\n",
    "        # take the last k transformer layers from the teacher\n",
    "        x = fwd_output.teacher_output.hidden_states[-self.num_hidden_layers_to_predict:]\n",
    "        # Follow the same layer normalization for all modalities\n",
    "        x = [torch.layer_norm(tl.float(), tl.shape[-1:]) for tl in x]\n",
    "        x = sum(x) / len(x)\n",
    "        # normalize targets\n",
    "        x = torch.layer_norm(x.float(), x.shape[-1:])\n",
    "    \n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # take the last k transformer layers from the teacher\n",
    "            y = fwd_output.teacher_output.hidden_states[-self.num_hidden_layers_to_predict:]\n",
    "            # Follow the same layer normalization for all modalities\n",
    "            y = [torch.layer_norm(tl.float(), tl.shape[-1:]) for tl in y]\n",
    "            y = sum(y) / len(y)\n",
    "            # normalize targets\n",
    "            y = torch.layer_norm(y.float(), y.shape[-1:])\n",
    "                \n",
    "        hidden_states_loss = self.loss_fn(x, y)\n",
    "        \n",
    "        x_pooler = fwd_output.student_output.pooler_output\n",
    "        y_pooler = fwd_output.teacher_output.pooler_output\n",
    "        pooler_loss = self.loss_fn(x_pooler, y_pooler) #TODO: check if this is correct\n",
    "        \n",
    "        loss = hidden_states_loss + pooler_loss\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4389)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = LatentPredictionLoss(num_hidden_layers_to_predict=2)\n",
    "loss(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = torch.nn.SmoothL1Loss(reduction='mean', beta=1.0)\n",
    "mse = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('multimodal-ssl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ac8a2bc69d4b2bdc42aaccd63f192d886c476dacd93adfa548f17911c905576"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
